\chapter{Introduction}
%\addcontentsline{toc}{chapter}{Introduction}
%\chaptermark{Introduction}



\section{Context and Motivation}
%\addcontentsline{toc}{section}{Context and Motivation}
%Context: Model-driven engineering, software evolution, metamodel evolution
%ToDo Add cost, benifits of using MDE
Software systems are increasingly growing in complexity, which leads to a substantial burden in terms of maintenance, often resulting in a high cost that may surpass the cost of software development itself \cite{https://doi.org/10.1049/sfw2.12075}.
Since Object Management Group (OMG) has introduced Model Driven Engineering in 2001 \cite{brambilla2017model}, MDE has been prominent in developing and maintaining large-scale and embedded systems while increasing the developers' productivity. By adopting MDE, industry can reduce time (development time and time-to-market), costs (development, integration, and reconfiguration), and improve sustainability and international competitiveness. %\cite{10.1145/1985793.1985858,10.1007/s10270-019-00757-6}. MDE raises the abstraction level to the "metamodel" artifact in order to separate the implementation from the business logic.
 In MDE, metamodel is a central artifact for building software languages \cite{cabot2012object}. It specifies the domain concepts, their properties, and the relationship between them.
A metamodel is the cornerstone to generate model instances, constraints, transformations, and code when building the necessary language tooling, e.g. editor, checker, compiler, data access layers, etc. 
In particular, metamodels are used as inputs for complex code generators that leverage the abstract concepts defined in metamodels. The generated code API is used for creating, loading and manipulating the model instances, adapters, serialization facilities, and an editor, all from the metamodel elements.
This generated code is further enriched by developers to offer additional functionalities and tooling, such as validation, transformation, simulation, or debugging.
For instance, UML\footnote{\url{https://www.eclipse.org/modeling/mdt/downloads/?project=uml2}}  and BPMN\footnote{\url{https://www.eclipse.org/bpmn2-modeler/}} Eclipse implementations rely on the UML and BPMN metamodels to generate their corresponding code API before building around it all their tooling and services in the additional code.
%Problem definition/challenges: The impact of metamodel evolution on the software artifacts, particularly, the code, the co-evolution of code.
\section{Challenges}
%\addcontentsline{toc}{section}{Challenges}
%In this specific context, we identified the following challenges to be our probelem scope:
\subsection*{C1: Resolve the impact of the metamodel evolution on the code automatically}
One of the foremost challenges to deal with in MDE is the impact of the evolution of metamodels on its dependent artifacts. We focus on the impact of metamodels' evolution on the code. 
Indeed, when a metamodel evolves and the code API is regenerated again, the additional code implemented by developers can be impacted.
	As a consequence, this additional code must be co-evolved accordingly.% by executing a resolution for each impacted part of the code.

However, manual co-evolution can be tedious, error-prone, and time-consuming. %Developers spend 30\% of their time in maintenance \footnote{https://blog.codacy.com/the-economics-of-code-quality}
%TODO : add statistics
%Therefore, it is essential to support an automatic co-evolution of code when metamodels evolve.
Therefore, experts tried through last decades to find more sophistic solutions to tackle the problem of co-evolution when metamodels evolve. This interest covered almost all the artifacts in MDE ecosystem not only the code, and many solutions were proposed, inter alia, raising the automation degree of the co-evolution. Note that other aspects treated in co-evolution problem like optimization and evolution resilience.
The co-evolution challenge has been extensively addressed in \emph{MDE}. 
%TODO CO-Evolution metamodel-other artifacts
% - the challenge of metamodels and code co-evolution.
In particular, \cite{riedl2014towards,kanakis2019empirical,pham2017bidirectional,jongeling2020towards,jongeling2022Structural,zaheri2021towards} focused on consistency checking between models and code, but not its co-evolution.
Other works \cite{yu2012maintaining,Khelladi2020} proposed to co-evolve the code. However, the former handles only the generated code API, it does not handle additional code and aims to maintain bidirectional traceability between the model and the code API. The latter supports a semi-automatic co-evolution requiring developers' intervention. Moreover, it does not use any validation process to check the correctness of the co-evolution and with no comparison to a baseline. In this thesis, we tackle the challenge of resolving the impact of the metamodel evolution on the code automatically followed by checking the correctness of the co-evolution.

 

\subsection*{C2: Behavioral correctness of the metamodel and code co-evolution}

In literature, when the problem of metamodel and code co-evolution is addressed, the challenge of checking that the co-evolution impacted or not the behavioral correctness of the code is not handled. In any Model-Driven Engineered system, the elements of the metamodel are used in the code. The evolution of the metamodel will be propagated in the code that is co-evolved and its behavior may be altered. Hence, the importance of checking the correctness of the co-evolution. In a larger scope, only few works were dedicated to check the correctness of a code evolution in general. %wether it is refactoring or co-evolution
%our approach can be categorized along the incremental test selection approaches, such as 
 Ge et al. \cite{10.1145/2568225.2568280} propose to verify the correctness of refactoring.
Out of the scope of testing code evolution, we find the incremental test selection approaches Infinitest\footnote{\url{https://infinitest.github.io/doc/eclipse}}, EKSTAZI~\cite{7203050}, and Moose~\cite{ducasse2000moose}. All of Infinitest, EKSTAZI and Moose aim to analyze code changes incrementally to select impacted tests in the evolved version of the code only.
%focus more on our contribution or not?

%Purpose of the study: 
%Research questions
%Summary of contributions
\subsection*{C3: How to draw benefit from LLMs for the metamodel and code co-evolution}
In the MDE ecosystem, we can consider that metamodel and code co-evolution is one of many other MDE tasks. For example Model generation and code generation. Since their appearance, LLMs have been applied in different domains of scientific research, such as Software Engineering and Model-Driven Engineering (MDE), however, to the best of our knowledge, the challenge of exploring LLMs in the task of metamodel and code co-evolution has not yet been addressed. In Software Engineering side, Fu et al. \cite{fu2023chatgpt} evaluated ChatGPT ability to detect, classify, and repair vulnerable code. Kabir et al. \cite{kabir2023empirical} evaluated ability of ChatGPT to generate code and to maintain it by improving it based on a new feature description to add in the code. Zhang et al. \cite{zhang2023multilingual} proposed Codeditor, an LLM based tool for code co-evolution between different programming languages. It learns code evolutions as edit sequences and then uses LLMs for multilingual translation.
Moreover, other studies focused on evaluating LLMs in MDE activities. 
Chen et al. \cite{10344012} and Camara et al. \cite{camara2023assessment} used ChatGPT to generate models.
Chaaben et al. \cite{chaaben2023towards} showed how using few-shot learning with GTP3 model can be effective in model completion and in other modeling activities. 
%
%TODO WHY it is a good idea to use llm in co-evolution
\section{Contributions}
%\addcontentsline{toc}{section}{Contributions}
To tackle these three challenges, we propose three contributions:
\begin{itemize}[label=\ding{212}]

	\item First, we propose a fully automatic code co-evolution approach due to metamodel evolution based on pattern matching. Our approach handles both atomic and complex changes of the metamodel. This approach is evaluated, on nine Eclipse projects from OCL, Modisco, and Papyrus, based on four actions: 1) Measuring the co-evolution correctness using automatically generated unit tests. 2) Verifying the behavioral correctness using unit tests running before and after automatic code co-evolution. 3) Comparison with the state-of-the art semi-automatic co-evolution approach~\cite{Khelladi2020}. 4) Comparison with Quick Fixes popular tool. The prototype implementation of an Eclipse plugin is available online (link).
	  Results show that our approach reached an average of 82\% of precision and 81\% of recall, varying from 48\% to 100\% for precision and recall respectively.
	
	
	\item Second, we propose an approach that assist developers to check the behavioral correctness of the co-evolution. This approach leverages unit tests before and after the co-evolution and gives visual report about passing, failing, and erroneous tests before and after the co-evolution. This visual report allow to have more insights about the co-evolution ans its impact on the code. We then evaluated our approach on 18 Eclipse projects from
	OCL, Modisco, Papyrus, and EMF using both automatically generated and manually written tests. When we studied the usefulness of our approach quantitatively, we found 88\% of reduction in the number of tests and 84\% in execution time.The prototype implementation of an Eclipse plugin is available online (link). The other part of the evaluation consisted of an user study experiment to gain evidence on the difficulty of the manual task of tracing impacted tests after metamodel
	evolution and co-evolution. 
	
	\item Third, we investigate the ability of LLMs in giving correct co-evolutions in the context of metamodel and code co-evolution. The prototype of implementation of an Eclipse plugin is available online (link). We evaluated our study approach with ChatGPT version 3.5 on seven Eclipse projects
		from OCL and Modisco evolved metamodels. the evaluation included temperature variation, prompt structure variation, and comparison with IDE Quick Fixes as baseline. Results show that ChatGPT can co-evolve correctly 88.7\% of the errors, varying from 75\% to 100\% of correctness rate. When varying the prompts, we observed increased
		correctness in two variants and decreased correctness in another variant. We also observed that varying the temperature
		hyperparameter yields better results with lower temperatures. Finally, we found that the generated prompts co-evolutions completely outperform the quick fixes.


\end{itemize}

%TODO Overall results. ok 

%TODO Thesis organisation
\section{Outline of the thesis}
This manuscript is organised as follows:
\begin{itemize}[label=\textbullet,font=\small]

\item Chapter 2 provides a short background about our MDE context and main concepts that will be employed throughout the thesis.
\item Chapter 3 focuses on a review of relevant studies carried out within Metamodel change detection, co-evolution in MDE ecosystem, API-client evolution, language evolution, and evolution in low-code platforms. This chapter ends with a discussion about limitations and research gap.
\item Chapter 4 is devoted to our first contribution about the automatic code co-evolution approach du to metamodel evolution. It presents the algorithm of pattern matching process that selects the appropriate resolution for each error. It presents also its evaluation and results.
\item Chapter 5 presents our second contribution about leveraging unit tests to check metamodel and code co-evolution behavioral correctness with its evaluation including the user experience that we conducted and results.
\item Chapter 6 details the empirical study that we conducted as last contribution about exploring LLMs in metamodel and code co-evolution context, with its evaluation and results.
\item Chapter 7 summarises the contributions of this work and discusses its limitations and  potential avenues for future work, thereby concluding this thesis.

\end{itemize}


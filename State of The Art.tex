\clearemptydoublepage
\chapter{Background}

\chaptermark{Background}
%What is model driven engineering
%Metamodeling: definition and tools
%Main concepts: metamodel, constraint, transformation,
%Automation in MDE
%Evolution in MDE
In this chapter, I introduce the necessary background for Model-Driven Engineering. In Section \ref{Metamodeling}, I present the activity of metamodeling and the involved artifacts. Section \ref{mde_automation} discusses the automation task related to the artifacts presented in Section \ref{Metamodeling}. I finish this chapter with a presentation of the evolution and co-evolution concept in the context of model driven engineering.
%define the terminology of the main concepts that we use. 
% We define the specific scope of problems addressed in this thesis
% and discuss the spectrum of problems that arise in this field. 
%TODO Terminology: Model-Driven engineering, co-evolution
% Metamodel, co-evolution, code, maintenance, refactoring

\section{Model-Driven Engineering}
\label{mde}
To develop a software, a list of specifications is given to the developers, to code the final product. This approach can work in the case of small projects. When the complexity of the software increases, more efficient approaches must be adopted. Model-Driven Engineering has proven its efficiency comparing to other engineering disciplines in developing hyper-complex systems \cite{1231146}.

%\boitemagique{Model-Driven Enginereering}{
\textit{Model-Driven Engineering (MDE)} is the systematic use of models as primary artifacts during a software engineering process. The usage of models allows more abstraction that helps in managing complexity. MDE includes various Model-Driven approaches to software development, including Model-Driven Architecture, Domain-Specific Modeling and Model-Integrated Computing~\cite{10.1145/1985793.1985882}. The first appearance of MDE-like approaches started in the 80's \cite{10.1007/s10270-005-0079-0}. Till today, MDE is still adopted  and a lot of work is being done in academia and industry \cite{Mohagheghi2009,mohagheghi2008proof,jongeling2022Structural,wortmann2020modeling}.



%}
%TODO detaills the benefits of MDE

%Details about MDE approach 
The goal of MDE is to improve productivity, quality, and maintainability by leveraging high level abstractions throughout the development process. MDE process includes many activities: metamodeling, model verification, code generation, model transformations, implementation, testing, and documentation. The metamodeling phase implied the experts of the domain who focus on the major key aspects of the problem rather than being concerned about the underlying programming language and the implementation. Moreover, it aims to improve communication between multi-disciplinary collaborators \cite{wortmann2020modeling}.
%about major key aspects of the problem statement rather than focusing on programming.
%Metamodeling and modeling langugaes

% MEtamodel def :
The metamodel represents the main artifact in MDE. There are many definitions of the concept "metamodel" that can be found in literature from Stahl et al. \cite{stahl2006model}:

\textbf{Definition 01}: \textit{A metamodel} describes concepts that can be used for modeling the model (i.e. in the instances of the metamodel).

\textbf{Definition 02}: \textit {Metamodels} are models that make statements about modeling. More precisely, a metamodel describes the possible structure of models in an abstract way, it defines the constructs of a modeling language and their relationships, as well as constraints and modeling rules, but not the concrete syntax of the language.

\textbf{Definition 03}: \textit{A metamodel} defines the abstract syntax and the static semantics of a modeling language. Analogously, like a written program instance (e.g., in c or java, etc.) conforms to a grammar, a model instance conforms to a metamodel.
% vice versa, each formal language, such as Java or UML, possesses a metamodel.

Seidewitz \cite{seidewitz2003models} gives another commonly used definition of \textit{metamodels} in MDE:

\textbf{Definition 04}: \textit{A metamodel} is a specification model for a class of systems under study where each system under study in the class is itself a valid model expressed in a certain modeling language.

\section{Metamodeling}
\label{Metamodeling}
%definition, related tasks and artifacts, usages in different languages, tools
%%
\textit{Metamodeling} is the process of metamodel creation. Metamodeling is done thanks to metamodeling languages (that is in turn described by a meta-metamodel) \ref{fig:mofmodellevels}.

Metamodeling must gather the whole  knowledge that is required to define, precise, and deal with MDE challenges in its different tasks \cite{wortmann2020modeling}, related to other artifacts shown in Figure \ref{fig:mde_ecosystem}:

%DSL/ sftware language 
%Construction of domain-specific modeling languages (DSLs): 
%The metamodeling activity includes other tasks:
\begin{itemize}
\item The construction of metamodel describes the abstract syntax of target (software languages, solution system).
\item Model validation: models are validated against the constraints defined in the metamodel. 
\item Model-to-model transformations: such transformations are defined as mapping rules between two metamodels.
\item Code generation: the generation templates refer to the metamodel of the "system". 
\item Tool integration: based on the metamodel, modeling tools can be adapted to the respective domain. 
\end{itemize}

\textcolor{blue}{
In the context of Domain-Specific Languages, DSMLs can be tailored via metamodeling to precisely match the domain's semantics and syntax. The concrete syntax that is, the concrete form of the textual or graphical constructs with which the modeling is done must represent the metamodel in an unambiguous way. Having graphic elements that linked directly to a familiar domain makes it easier to learn and allows domain  experts to contribute, such as system engineers and experienced software architects, ensure that software systems meet user needs \cite{volter2013model}. The metamodel is the basis for the automated, tool-supported processing of Metamodeling models. On the other hand, a suitable concrete syntax is the interface to the modeler and its quality decides what degree of readability the models have \cite{stahl2006model}.
}
%Metamodeling tools/languages/techniques examples :

%// Add figure?

Metamodeling languages are classified into two categories, namely linguistic and ontological \cite{gavsevic2007metamodeling}. Linguistic metamodeling represents a way for defining modeling languages and their primitives (e.g., Object, Class, MetaClass) on the layer of a metamodel. Ontological metamodeling aims to represent domain knowledge accurately, it is concerned with semantics and meaning, e.g., OWL\footnote{https://www.w3.org/TR/owl-features/}. Linguistic metamodeling aims to define a language for creating models. it is concerned with syntax and structure.
I can use a different classification by purpose: General Purpose Modeling Languages and Domain-Specific Modeling Languages~\cite{de2012domain}. General Purpose Modeling Languages as for example : UML and its variants, generic metamodeling frameworks, such as MOF \footnote{https://www.omg.org/mof/}, and Ecore \footnote{https://eclipse.dev/modeling/emft/search/concepts/subtopic.html}. As examples of DSLs, I cite sysML and EXPRESS DSL (ref).

In MDE, there are language workbenches that are used for language creation, such as Xtext, MetaEdit+ \cite{wortmann2020modeling}.
% Add figure for above languages/techniques/frameworks

%\textbf{Generated artifacts, artifacts linked to the metamodel}


%Metamodel is the backbone in model driven engineering. 
In the language modeling ecosystem, other artifacts are created by the mean of the metamodel. By definition, a model is an instance of a metamodel, which means that the metamodel defines the concepts with which a model can be created. The created models can also be validated through a set of constraints to check the models' correctness. Constraints are written in Object Constraint Language. They precise specifications on the model that cannot be  expressed by diagrammatic notation. In order to save effort and avoid errors, models transformation is one of the common automated tasks in Model-driven engineering. Model transformation are expressed in  Transformation Languages for example, ATL). A transformation consists of a set of rules that map the source metamodel elements to the metamodel target’s elements. All of these artifacts have its specific tools and represent an important topic of research in MDE.

%// Add example of Metamodel+ model+constraint+transformation ?

%ex constraint : the age of a person is not negative, a person is younger than its parents
%Automation in the ecosystem
%code gen 
%tests
\section{Automation in the MDE ecosystem}
\label{mde_automation}
%Brief description about automated tasks in MDE.
 Automation plays a pivotal role within the MDE ecosystem. It is considered as one of the most important advantages of MDE. This section explores the significance of automation in MDE, particularly in the code generation activity and during the evolution of the metamodel cornerstone artifact. , its impact on the development lifecycle.% and key strategies for achieving efficient model-driven processes.

\subsection{Code Generation}

One of the most important activities in MDE is the code generation activity is recurrent, and its automation enhances the productivity and the cost.
For example, Eclipse Modeling Framework built-in code generator allows to generated a java API from an Ecore metamodel. The generated code API structure and technical choices are done to fit Java programming language and Model-Driven Engineering abstraction standards/principles (e.g., each metaclass is used to generate an interface and concrete implementation class that extends the generated interface, pattern observer).
% to have an efficient as possible
 The annotation \textit{@generated} is used to mark generated interfaces, classes, methods, and fields. This annotation can be used to differentiate the generated code from the manually written one.

In Eclipse Modeling Framework, two model resources (files) are manipulated: the .ecore file that contains  XMI serialization of the Ecore model and the .genmodel for the serialized generator model. The Ecore file is the document that contains the metamodeled main concepts that are used in code generation process.

\textcolor{blue}{Develop this paragraph?}
\subsection{Evolution in the MDE context}

During the software development process, software artifacts are meant to be changed, due to many reasons: client requirements and domain specifications, software maintenance, or bug correction. Like any other software system, modeling languages are the subject of an inevitable evolution, during their process of building, multiple versions are developed, tested, and adapted until a stable version is reached. 

Different types of evolution are categorized depending on the impact and purpose of the applied modifications \cite{lientz1980software,Swanson1976}:
\begin{itemize}
	
	\item  Corrective: aims to correct discovered problems and inconsistencies, such as processing failures, performance failures, or implementation failures by applying a set of reactive modifications of a software product.  
	
	\item  Adaptive: in case of changing environment, such as changes in data environment or processing environment, this evolution aims to keep a software product usable.
	
	\item Perfective: this evolution aims to improve functionalities, to enhance the performance, reliability, or to increase the maintainability of a software.  
	
\end{itemize}
It is unavoidable to change, whether to answer to requirement modifications and/or technological progress.
The term \textit{Evolution} can be refined as the literature presents various related terms like: Maintenance, Refactoring, and \textbf{Co-evolution}, which are different types of modifications that could be applied on a software.

%/Why we need to perform evolution ?
%examples?
%TODO Add defs references

\textbf{Evolution}: any adaptation that occurs in the software in response to new requirements. These requirements are the consequence of the past experience of the users that feeds the developers' learning. \cite{bennett2000software}. 

\textbf{Maintenance}: It is modifying a software product after delivery to correct faults, to improve performance, or to adapt the product to a changing environment \cite{schneidewind1987state}.

\textbf{Refactoring}: It is an oriented object term, that means modifications of software to make it easier to understand and to change or to make it less susceptible to errors when future changes are introduced \cite{mens2004survey}. 

\textbf{Co-evolution}: It consists of the process of adapting and correcting a set of artifacts $A_1$, $A_2$, ...$A_N$ in response to the evolution of an artifact B on which $A_1$, $A_2$, ...$A_N$  strongly depend, for example the co-evolution of models with the evolving metamodel as used in Kessentini et al. paper \cite{Kessentini2016automated}, and the co-evolution of API/client as used in Eilertsen et al. paper \cite{8443581} .

Coupled evolution \cite{herrmannsdoerfer2009cope}
\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.6\linewidth]{./pics/soaPics/mofmodellevels.png}
	\end{center}
	\caption{MDA’s Modeling Level Hierarchy}
	%	{\footnotesize Titre plus long avec des explications.}
	\label{fig:mofmodellevels}
\end{figure}
%\begin{figure}[htbp]
%	\begin{center}
%		\includegraphics[width=0.6\linewidth]{./pics/soaPics/solicy.png}
%	\end{center}
%	\caption{Software Life Cycle ( not sure to include)}
%	{\footnotesize Titre plus long avec des explications.}
%	\label{fig:softwarelifecyle}
%\end{figure}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.6\linewidth]{./pics/soaPics/mdeecosystem.png}
	\end{center}
	\caption{MDE Ecosystem ( not sure to include)}
%	{\footnotesize Titre plus long avec des explications.}
	\label{fig:mde_ecosystem}
\end{figure}


%definition
\chapter{State Of The Art}

\chaptermark{State Of The Art}
%offline and online process
In this chapter, I present an overview of what has been done in the field of code co-evolution in the context of Model-Driven Engineering. I split this overview into five  parts. In section \ref{changedetection}, I present the metamodel change detection approaches. Section \ref{coevolutionartifacts} presents the co-evolution of model, transformations, constraints with evolving metamodel. In section \ref{coevolutioncode}, I discuss code co-evolution and relevant literature about API-client evolution, and language evolution. In Section \ref{behavioralcorrectness}, I browse related work to checking the behavioral correctness of code co-evolution. Section \ref{llmsforcoevolution}, presents an overview of the use of LLMs in related MDE and SLE tasks. I finish this chapter with a discussion focused on limitations and research gap.
 \section{Metamodel change detection}
 \label{changedetection}
 One of the intrinsic properties of software artifacts is its continuous evolution ~\cite{mens2008introduction}. Like any software artifact, metamodels are meant to evolve to meet the represented domain. %one key sentence of the context
 In this thesis, our context is triggered by the metamodel evolution, that's why I find essential to understand this evolution in detail.
 %metamodel diffing
 A lot of work has been done on metamodel diffing.
 Detection approaches can be classified into two main categories; online\footnote{Offline approaches perform detection after the metamodel has been evolved.} detection approaches, and offline\footnote{Online approaches perform instant detection for each change during the metamodel evolution} detection approaches. This classification can be refined using some factors as detailed by Hebig et al. \cite{hebig2016approaches}: automation degree, types of detected changes, considered issues (overlap, indefinite length, hidden changes, order of changes, and undo operations)\cite{hebig2016approaches}.
 
 %breaking not breaking?
 
  Furthermore, many of them classified the detected changes based on their impact on the treated artifact (e.g., models, constraint, transformation, and code). I table \ref{table:changesCatalog} I put the largest set of changes types that I found in literature \cite{herrmannsdoerfer_extensive_2011}. Later in Section \ref{sec: ap1_changedetection}, I will specify the treated subset of these changes. 
  %with their possible impact on the code.
 
 
 Two types of evolution changes are considered when evolving a metamodel: \emph{atomic} and \emph{complex} changes~\cite{hebig2016approaches,Herrmannsdoerfer2011}. 
 Atomic changes are additions, removals, and updates of a metamodel element. Complex changes consist of a sequence of atomic changes combined together~\cite{vermolen_reconstructing_2012},~\cite{khelladi2015detecting}. For example, move property is a complex change where a property is moved from a source class to a target class. This is composed of two atomic changes: delete property and add property~\cite{Herrmannsdoerfer2011}. 
 Many approaches in the literature~\cite{Alter2015, williams2012searching,cicchetti_managing_2009,langer_posteriori_2013,vermolen_reconstructing_2012,Khelladi2016,bettini2022executable} exist to detect metamodel changes between two versions.
%  \begin{table*}[t]
%  		\caption{Catalog of changes that occur during the metamodel evolution. (To fill)}
%  	\label{table:changesCatalog}
% \vspace{1em}
% 	\begin{tabular}{ |c|c|c| } 
% 	
% 		\hline
% 		Type & group  & Change name \\
% 		\hline
% 		\multirow{4}{4em}{ Atomic changes} & Delete class  \\ 
% 		& Delete property \\ 
% 		& Add class \\ 
% 		& Add property \\ 
% 		& Rename class \\ 
% 		& Rename property \\ 
% 		& Generalize property \\ 
% 		\hline
% 		\hline
% 		\multirow{5}{4em}{Complex changes} & Move property \\ 
% 		& Push property  \\ 
% 		& Pull property\\ 
% 		& Inline class\\
% 		& Change property type\\
% 		\hline
% 		
% 	\end{tabular}
% 	\end{table*}
% 	\vspace{1em}
% 	
 	
 	  
 	
 	\begin{table*}[t]
 		\centering
 		\caption{Catalog of model operators} 
 		\label{table:catalogofchanges}
 		\resizebox{16cm}{!} {
 			{\small
 				\begin{tabular}{l|c|c}%|l|l|l|l|l|l|l|}
 				%\hline
 				\toprule 
 				Type & group  & Change name  \\ \midrule
 				
 				\multicolumn{1}{l|}{ Atomic changes}
 				 & \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}} Structural \\ Primitives\end{tabular} } 
 				 &  \begin{tabular}[c]{@{}l@{}} Create Package, Delete Package, Create Class,\\Delete Class, Create Attribute, Create Reference,\\ Delete Feature,change type, Create Opposite Ref.,\\Delete Opposite Ref., Create Data Type, \\Delete Data Type, Create Enum, Delete Enum, \\Create Literal,Merge Literal  \end{tabular}
 				 \\  \cmidrule{2-3} 
 				 & \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}} Non Structural \\ primitives\end{tabular}} 
 				&  \begin{tabular}[c]{@{}l@{}} Rename, Change Package,Make Class\\ Abstract, Drop Class Abstract,\\ Add Super Type, Remove \\Super Type, Make Attr. Identifier,\\ Drop Attr. Identifier, Make Ref. Composite, \\Switch Ref. Composite, Make Ref. Opposite,\\ Drop Ref. Opposite  \end{tabular}
 				\\   \cmidrule{1-3} 
 				\multicolumn{1}{l|}{ Complex changes}
 				& \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}} Specialization / \\Generalization Operators\end{tabular} } 
 				&  \begin{tabular}[c]{@{}l@{}} Generalize Attribute, Specialize \\ Attribute, Generalize Reference, \\Specialize Reference, Specialize\\ Composite Ref. Generalize Super Type,\\ Specialize Super Type \end{tabular}
 				\\  \cmidrule{2-3} 
 				& \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}} Inheritance \\Operators
 						\end{tabular}} 
 				&  \begin{tabular}[c]{@{}l@{}}  Pull up Feature, Push down Feature,\\ Extract Super Class, Inline Super Class, \\Fold Super Class, Unfold Super Class,\\ Extract Sub Classn Inline Sub Class \end{tabular}
 					\\  \cmidrule{2-3} 
 				& \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}} Delegation\\ Operators\end{tabular}} 
 				&  \begin{tabular}[c]{@{}l@{}} Extract Class, Inline Class, Fold Class,\\ Unfold Class, Move Feature over Ref.,\\ Collect Feature over Ref.  \end{tabular}
 				
 				\\  \cmidrule{2-3} 
 				& \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}} Replacement\\ Operators\end{tabular}} 
 				&  \begin{tabular}[c]{@{}l@{}} Subclasses to Enum., Enum. to Subclasses,\\ Reference to Class, Class to Reference, \\Inheritance to Delegation, Delegation to Inheritance,\\ Reference to Identifier, Identifier to Reference \end{tabular}
 				\\  \cmidrule{2-3} 
 				& \multirow{2}{*}{ \begin{tabular}[c]{@{}l@{}}Merge /\\ Split Operators Merge\end{tabular}} 
 				&  \begin{tabular}[c]{@{}l@{}} Merge Features, Split Reference by Type,\\ Merge Classes, Split Class, Merge Enumerations\\\end{tabular}
 				\\
 				
 			\\
 				
 				\bottomrule
 				
 				% &  \cellcolor{CellColor1} \CIRCLE & \cellcolor{CellColor1}  &  \cellcolor{CellColor1}\CIRCLE & \cellcolor{CellColor1}\CIRCLE \\ \bottomrule
 				\end{tabular}
 			}
 		}
 	\end{table*}
 				
 In Model-Driven Engineering area, metamodel changes can be divided into three categories\cite{gruschko2007towards}:
 \begin{itemize}
 	
 \item	Non-breaking changes that occur in the metamodel but do not break other artifacts of lower abstraction level.%can be resolved automatically.
  \item Breaking and resolvable changes break the conformance of existing data, although they can be automatically adapted.
 \item Breaking and unsolvable changes break the conformance of existing data, that cannot be automatically adapted, and require user intervention.
 \end{itemize}
 	In API evolution context, API changes can be classified as Non-breaking API Changes	or Breaking API Changes. A breaking change is not backward compatible. In this case, client code calling the evolved API by a Breaking Change fails to compile or may behave differently at runtime. A non-breaking change is backward compatible. This kind of changes aims to extend the functionalities or fix errors \cite{dig2006apis}.
 	
 	
 	

%TODO Discussion part 

%operation-base ?difference-based

All these approaches propose structural changes detection: Additions, deletions, or modifications to classes, attributes, associations, or inheritance structures.
Definition of metamodel: definition of the structural side of the representation of the given domain. Behavioral side is given through constraints. Following this definition, in this section, I give the structural changes. Another usage ? behavioral impact ? structural impact? structural error ? behavioral error? static/ runtime? 


 

Demuth et al. \cite{demuth2015constraint}, Herrmannsdoerfer et al. \cite{herrmannsdoerfer2009cope}, Khelladi et al. \cite{khelladi2016detecting} are online approaches. These approaches take into consideration undo operations.
Where other approaches \cite{williams2012searching,10.1145/2000410.2000416,levendovszky2014semi,garces2009managing,cicchetti_managing_2009,langer_posteriori_2013,garcia2012model,xing2006refactoring,moghadam2012automated,vermolen_reconstructing_2012} are offline.  Offline detection may cause an order issue, particularly in \cite{williams2012searching,10.1145/2000410.2000416,levendovszky2014semi,garces2009managing,langer_posteriori_2013,garcia2012model,xing2006refactoring,moghadam2012automated}. 
All of them do not consider hidden changes except Vermolen et al. \cite{vermolen_reconstructing_2012}.


Herrmannsdoerfer et al. \cite{herrmannsdoerfer2009cope} and
Williams et al. \cite{williams2012searching} are manual. Di Ruscio et al. \cite{10.1145/2000410.2000416}, Vermolen et al. \cite{vermolen_reconstructing_2012}, and Khelladi et al. \cite{khelladi2016detecting} are all semi-automatic that require user decision to select final output changes.
Demuth et al. \cite{demuth2015constraint}; Levendovszky \cite{levendovszky2014semi},Cicchetti et al. \cite{cicchetti_managing_2009}, Garces et al. \cite{garces2009managing}, Langer et al. \cite{langer_posteriori_2013}, Garcia \cite{garcia2012model}, Xing  et al. \cite{xing2006refactoring}, Moghadam et al. \cite{moghadam2012automated} are full automatic approaches.




Moghadam \cite{moghadam2012automated}, Vermolen \cite{vermolen_reconstructing_2012} and \cite{khelladi2016detecting} take into consideration indefinite length of a complex change.
Khelladi et al. \cite{khelladi2016detecting} take into consideration overlap issue.


%Structural Changes: Additions, deletions, or modifications to classes, attributes, associations, or inheritance structures.
%Semantics or Behavioral Changes: Modifications in the constraints, rules, or behavior definitions in the metamodel.


After studying the literature change detection approaches of metamodel, I found that Khelladi et al. \cite{khelladi2016detecting} handle all type of changes. Furthermore, their approach handle all the issues that I mentioned. 
It is a semi automatic approach but this adds a trust value to the approach because automatic approach may have order or overlap issues.

Another reason to choose khelladi2016detecting approach is their output representation and vocabulary. It required a minimum effort of adaptation because I use the same changes representation.

The usage of Khelladi et al. \cite{khelladi2016detecting} in my work is explained in section??

 \section{Co-evolution of models, constraints, and transformation}
 \label{coevolutionartifacts}
% In MDE ecosystem, the metamodel is the starting point to have other artifacts that we defined in section ?.
  In this section, I will present an overview of the existing work about these artifacts co-evolution. Note that if the solution is applied during the evolution of the metamodel, we call it an online solution, otherwise it is offline.
 The comparison, advantages, and drawbacks of the presented approaches is out of the scope of this dissertation.
 
\subsection{Metamodel and model co-evolution}
Due to metamodel evolution, the model becomes no conformant. A set of resolutions are applied to co-evolve the model to gain again its conformity to the metamodel.
 %  - COPE - Automating Coupled Evolution of Metamodels and Models : couple evolution co-evolution
Two strategies to evolve models due to metamodel evolution. 
The first strategy, the metamodel is the artifact to be adapted in a way that the old models can still be used with the evolved modeling language without adapting the models \cite{herrmannsdoerfer2009cope}. This approach suggest the resilience of the models. The second strategy adapts the metamodel in a breaking manner for the models, that must be adapted by transforming them into a new version that conforms to the adapted metamodel.

%change order, resolution order
%Once the metamodel changes are detected, using one of the previously presented approaches in Section ?, 
 %a set of resolutions are applied to co-evolve the model to gain again the conformity to the metamodel.
 %change order, resolution order
 The co-evolution between metamodel and models can be processed manually but it requires a huge expertise, and when the number of models to co-evolve increases, manual co-evolution becomes hard task. 
 Most of automatic and semi-automatic co-evolution  approaches use automatic or manual diffing metamodel approaches in their solutions. Model co-evolution approaches that exist can be categorized into five categories \cite{Hebig2017}. The first category is Resolution Strategy Languages that specifies in a transformation language how to update the model given the list of metamodel changes \cite{10.1007/978-3-540-87875-9_44,sprinkle2004domain,wimmer2010using,10.1007/978-3-642-30476-7_13,10.1007/978-3-642-38883-5_10,10.1007/s10270-012-0313-5,10.1007/s10270-012-0296-2}. The category Resolution Strategy Generation groups approaches that generate full or partial resolution for each metamodel change \cite{del2007semi,de2008generating,garces2009managing,meyers2011generic,anguel2014using}.
 
 
 The third group of "Predefined Resolution Strategies" contains approaches that provide automation, when it is possible, by applying predefined resolution strategies \cite{hossler2005coevolution,florez2012coevolution,fernandez2013adapting,wachsmuth2007metamodel,cicchetti2009managing,van2011generic,becker2007process,herrmannsdoerfer2009operation,wittern2013determining}. 
 
 %We find three categories of metamodel and model co-evolution approaches.% Approaches based on resolution strategy languages that propose transformation languages created given the metamodel changes. The second category groups Resolution strategy generation approaches that allow to generate full or partial resolutions for each metamodel change.
 
  Some of these approaches requires user intervention to make decision on the selected operation to adapt the model.
  The fourth category of Resolution Strategy Learning that adopts machine learning algorithm to select the resolution strategy for metamodel changes.\cite{anguel2013towards}.%TODO Look for full paper
 
The fifth and last category is called Constrained Model Search. It groups approaches that do not use the metamodel change, but uses the original model and the new metamodel to apply a constrained-based search of valid model variants \cite{demuth2016co,gomez2014approach,schonbock2014care}. Other approaches consider the model co-evolution problem as an optimization one that does not need the list of changes of the metamodel \cite{kessentini2016automated,kessentini2019automated,kessentini2020interactive}.
%Demuth el al. [6] who used it for models co-evolution.
% There are also approaches for semi-automatic co-evolution of models that rzquires the user intervention to make decision on the selected operation to adapt the model.

%The point is that for metamodel and model co-evolution; predefined approaches exist, full automatic approaches exist to put in the discussion


%For example, when a type restriction is applied to a property in a metamodel, the generic solution implemented in the approaches of Meyers et al. and Edapt would delete prop- erty instances that are no longer conform. In contrast, the approach of Wachsmuth would allow the user to specify a type conversion. Thus, due to giving additional control to the user, the property values can be preserved in the mod- els. Consequently, if there is the need for an outcome that deviates from generic solutions, approaches are required to provide the user with a certain amount of control about the results of the resolution

Depending on whether a user intervention is need or not to apply predefined or generated resolutions, we distinguish automatic and semi-automatic approaches.
Di Ruscio et al. \cite{10.1007/978-3-642-33654-62},MCL (Levendovszky et al. \cite{levendovszky2014semi}, Anguel et al. \cite{anguel2014using},cicchetti et al. \cite{cicchetti2008automating}, brand et al. \cite{van2011generic}, CBRMig\cite{anguel2013towards} are automatic model co-evolution approaches.

Semi-automatic approaches that I find in literature are: de Geest et al. \cite{de2008generating},  Garcès et al \cite{garces2014adapting}, Wittern et al. \cite{wittern2013determining} (for atomic changes, the co-evolution is automatic, for complex changes, the co-evolution is manual).

%semi-automatic vs automatic : trade-off between desired correctness of the resulting models and automation that khelladi survey cite an example of a property type restriction. Some approaches would delete the property instances that are no longer conform where other approaches propose a type conversion. 


COPE \cite{herrmannsdoerfer2009cope}, and Wachsmuth et al. \cite{wachsmuth2007metamodel}, Kessentini et al. \cite{kessentini2018integrating,kessentini2020interactive} do not explicitly study the impact of metamodel evolution on  models.
 
 Cicchetti et al. \cite{cicchetti2008automating} categorize metamodel modifications  into additive, subtractive, and updative. Their approach starts by generating a difference model, then a transformation model to co-evolve models, without a step dedicated impact analysis.
Garcès et al. \cite{garces2009managing} computes equivalences and differences between any pair of metamodels, simple and complex changes. These equivalences and differences are then represented as matching model. In the second step, the matching model is translated into an adaptation transformation by using a Higher-Order Transformation (HOT) that is later executed. A matching model is used to generate a transformation model but no explicit analysis for the impact if metamodel evolution on the models.

Demuth et al.\cite{demuth2016co} consistent change propagation focuses on maintaining consistency between artifacts (metamodel itself and existing models ). Impacted constraints are used to propose repairs ( to regain model conformance), then manual intervention is needed to select and apply these repairs. ( metamodel changes are propagated through constraints that are used to repair moodel inconsistencies (by model and possible modification of metamodel)

 

%\cite{kessentini2018integrating,kessentini2019automated,cicchetti2008automating,herrmannsdoerfer2009cope,garces2009managing,wachsmuth2007metamodel},
\subsection{Metamodel and constraints co-evolution}
Another artifact that depends on the metamodel and needs to be adapted to the evolution of its metamodel is Constraints.
 Constraints co-evolutions that exist in literature may be online \footnote{Online approaches perform instant co-evolution for each change during the metamodel evolution} or offline \footnote{Offline approaches perform co-evolution after the metamodel has been evolved.}. Every approach has its own co-evolution mechanism that treats specific types of metamodel changes and has its automation degree. Demuth et al. \cite{10.1007/978-3-642-41533-3_18} proposed a template-based, that cannot cover all changes types, of the predefined structure of the updated constraint. Markovich et al. \cite{markovic2008refactoring} proposed refactoring rules that depend on the impact of UML class diagram evolution on the constraints. In this approach, the user select the refactoring rule to be applied on the model then on the depending constraints.. Hassam et al. \cite{hassam2011assistance} propose METAEVOL, based on a transformation language. Kusel et al. \cite{kusel2014systematic} propose a solution for the co-evolution of the constraint body and do not include its context that may need co-evolution also.
 Cabot et al \cite{cabot2004automatic} treats OCL constraints co-evolution due to metamodel deletion change. Khelladi et al. \cite{khelladi2017semi} proposed an approach that record the metamodel atomic and complex changes in a chronological order then apply one or many resolutions to co-evolve the constraints. Batot et al. \cite{8101267} tackle the constraint co-evolution problem as  an multi-objective optimization problem and apply heuristic-based recommendation approach that does not require/use a predefined set of transformation rules/resolutions to co-evolve the constraints.
 
 
% Describe what have been done in analysing the impact of metamodel evoluitoon on the constraits , and how the co-evolutinon correctness is checked becausie constrains are behavioral description of the metamodel.
 Kusel et al. \cite{kusel2014systematic}  studies the impact of metamodel evolution on OCL expressions. They distinguished between breaking and non-breaking impact. moreover, they divided the changes into three groups : constructives are non breaking where destructive changes, and updative changes are breaking changes. These breaking changes, are considered so if they have at least one breaking impact case. They give a table that contains every possible case, whether it is breaking or not and the corresponding resolution. This paper proposes syntactic co-evolution that can be checked by a compiler, where the semantic co-evolution correctness is checked through “Pattern-based formal specification Modeling Language for Model Transformations” (PaMoMo)\cite{10.1007/s10515-012-0102-y}. a set of Pamomo specifications (input models) are verified before and after OCL expressions' co-evolution. Pamomo states. properties the models must fulfill

Batot et al. \cite{batot2017heuristic} register metamodel elements that were deleted, added, or had their multiplicity changed between the two versions. Computing atomic differences does; but does not require high level changes identification. They do not explicitly analyze the impact of metamodel evolution on OCL constraints. Their goal is to satisfy the objectives of NSGA II  but no more checking is done. it proceed to syntactic comparison to determine if a candidate constraint is the same as the expected one.
  
   
  Demuth, markovitch, cabot \cite{10.1007/978-3-642-41533-3_18,markovic2008refactoring,cabot2004automatic} their approaches ar fully automatic while Hassam, kusel and Khelladi, and Batot \cite{hassam2011assistance,kusel2014systematic,khelladi2017semi,8101267} propose semi-automatic approaches since the user must select from the recommended output constraints. 
 
%impact analysys: 
Hassam et al \cite{hassam2011assistance} proceed by a partial impact analysis, through a table that contains  constraint context that is linked with the involved elements of mm that is evolved, the designer is responsible to check the validity of the constraint. 

Khelladi et al. \cite{khelladi2017semi}  associate each evolved metamodel element to impacted (context and body ) and precise impacted astnodes in a table. no further checking

Other approaches do not study the impact of metamodel evolution on the constraint artifact like Batot et al. \cite{8101267}.

Cabot et al. \cite{cabot2004automatic} as an impact analysis, identify of the elements to be deleted (those selected by the user plus all the elements affected by them)
Cherfa et al. \cite{cherfa2021identifying}  provide an assistance to developers OCL constraint co-evolution, by focusing on the structures in the metamodel that potentially cause problems and which need new OCL constraints after the co-evolution). Their approach no explicitly process an impact analysis.%instead of exploring the solution domain (generating the missing constraints), /
%Since the set of constraints (F) is incomplete and hence does not cover all the concepts of the new metamodel version, a set of MIS that can arise from the evolution operators. implies the designer  in treating these mis.
 
\subsection{Metamodel and transformations co-evolution}

Almost all the existing transformation approaches that I find in literature have the same strategy. This strategy consists of evolving the impacted parts in the transformations.
%start by analyzing the impact of the metamodel on the model transformations.
Mendez et al. \cite{mendez2010towards}, Ruscio et al. \cite{di2011needed}, Garces et al.\cite{garces2014adapting}, Kusel, et al.\cite{kusel2015consistent}, and khelladi et al. \cite{khelladi2018change} proposed to co-evolve impacted transformations with a set of resolutions. T
Mendez et al. \cite{mendez2010towards}, Ruscio et al. \cite{di2011needed}, khelladi et al. \cite{khelladi2018change} while they propose to evolve impacted transformation, no impact analysys is explicitly studied. Garces et al.\cite{garces2014adapting} explains the impact of the evolution of the metamodel on the transformations through a motivating example but not an explicit study inddepend from the example.they are semi-automatic approaches.

Garcia et al.\cite{garcia2012model} proposed an ATL transformation-based approach, which means that their resolutions are ATL transformations. This approach only guarantees that the transformation is syntac-
tically correct, mention that any other correctness properties, inclusing semantic correctness is not taken into consideration.
 Kusel, et al.\cite{kusel2015consistent} explained explicitly that his approach verify semantic correctness by properties expressed in PaMoMo language as a kind of regression testing.

The approach of khelladi et al. \cite{khelladi2018change} covers the largest set of possible resolutions whereas Ruscio et al. \cite{di2011needed}, estimate the cost of the co-evolution to decide about the co-evolution. They further explored the variability of the co-evolution due to the possible alternative resolution. All the approaches propose unique resolution to co-evolve each transformation.
Ruscio et al. \cite{di2011needed} approach allows developers to manually replace or refine a resolution. Khelladi et al. \cite{khelladi2018change}  in their ()change probagatoion-based approach,   allow to compose existing resolutions into a new one. This approach does not process any semantic verification of the transformation co-evolution.
Kessentini et al. \cite{kessentini2018automated} followed a different approach that does not use the changes of the metamodel as input and does not process an impact analysis, but rather uses a search-based approach that relied on multi objective heuristic algorithm NSGA-II. This approach has an objective function to minimize the number of errors of non-conformance between the metamodels and transformations. These errors can be statically detected by static semantic constraints.(no semantic verification of the approach's correctness).


% kusel2015consistent: formal specification language to describe correct- ness requirements for transformations (cf. [7] for details). A PaMoMo specification consists of declarative visual patterns, which may be positive, i.e., describing necessary conditions to occur (denoted by a “P”), or negative, which state forbidden situations (denoted by an “N”). Patterns are composed of two compartments containing object graphs typed on the source MM (left compartment) or target MM (right compartment). Objects in the source and target compartments may have attributes that may be assigned either a concrete value or a variable. A variable may be assigned to several attributes to ensure equality of their values. The specified patterns provide a well-defined operational semantics on basis of QVT- Relations [17], which allows to check whether pairs of input models and resulting output models fulfill the specified cor- rectness requirements, which in consequence allows to evalu- ate the semantic correctness of a transformation definition
Eventhough I consider the co-evolution in larger diameter in Model-Driven Engineering, my main focus is given to the co-evolution of the code that I detail in next section.


 \section{Code co-evolution}
 \label{coevolutioncode}
 I divided the related work to code co-evolution  into four (4) main categories : 1) Metamodel and code co-evolution, 2) API and client code co-evolution, 3) Automatic Program repair, and 4) Consistency checking. 
 \subsection{Metamodel and code co-evolution}
 %by the fact that the code and other artefacts (models, constraints, etc) are on different levels of asbtractions In fact, the models and constriats are on closer level of abstraction of the metamodel, where each metamodel element is directly referenced/present in the depending artefacts.However, the code is on a lower level of abstraction where each  metamolde element has differents representation in the code.Thus One change in a ..... will affect n .....
 
 Co-evolution of code is distinguished from the co-evolution of other artifacts. This distinction is due to by the fact that the code and other artifacts (models, constraints, transformations) are on different levels of abstraction. In fact, the models and constraints are on closer level of abstraction of the metamodel, where each metamodel element is directly referenced/present in the depending artifacts. However, the code is on a lower level of abstraction where each  metamodel element has different representation in the code.Thus $one$ change in a metamodel element will affect $n$ different code elements, in contrast to a $one$ to $one$ impact relationship between metamodel elements and models, constraints and transformation elements~\cite{kessentini2018integrating,kessentini2019automated,cicchetti2008automating,herrmannsdoerfer2009cope,garces2009managing,wachsmuth2007metamodel,batot2017heuristic,khelladi2017semi,correa2007refactoring,kessentini2018automated,khelladi2018change,garces2014adapting,10.1007/978-3-642-36089-3_9,kusel2015consistent,kusel2015systematic}.
 
 Yu et al.~\cite{yu2012maintaining} proposed to co-evolve the metamodels and the generated API in both directions. However, they do not co-evolve the code on top of it.% which our approach does. 
 %
 Khelladi et al.~\cite{Khelladi2020} proposed an approach that propagates metamodel changes in the code as a co-evolution mechanism. However, it is based on static analysis to detect the impacts and not on the actual errors that appear from the compilation of the code after the metamodel evolution. It further applies a semi-automatic co-evolution requiring developers' intervention, and without checking behavioral correctness with tests with no comparison to a baseline. 
 
 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \subsection{API and client code co-evolution}
 \label{API_evolution}
 
 %In this paper, we focus so far the co-evolution on the direction metamodel to code, which is not trivial. 
 
 Existing approaches for code migration are related to our work. % We focus on the main existing approaches to compare them with our approach.
   Henkel et al.~\cite{henkel2005catchup} proposed an approach whose implementation is called CatchUp!, it captures refactoring actions of the library and replays them on the code to migrate. However, they support only the changes renames, moves, and type changes. 
 
 Nguyen et al. \cite{nguyen2010graph} also proposed an approach that guides developers in adapting code by learning adaptation patterns from previously migrated code. Similarly, Dagenais et al.~\cite{dagenais2011recommending,5070565,10.1145/1932682.1869486} also use a recommendation mechanism of code changes by mining them from previously migrated code. 
 %
 Anderson et al.~\cite{andersen2010generic} proposed to migrate drivers in response to evolutions in Linux internal libraries. It identifies common changes made in a set of files to extract a generic patch that can be reused on other code parts. Gerasimou et al. \cite{10.1145/3194793.3194798} extract a set of mapping rules and apply code-based transformations to update its clients.
 
 % Survey about Library evolution \cite{10043250}
 
 Zaitsev et al.\cite{10043250}, present a survey about library evolution, that involves developers from Two Industrial Companies:Arolla and Berger-Levrault, and Pharo as an Open-Source Community. In this survey, the study was conducted in both perspectives :client side and library side. Kula et al. \cite{10.1016/j.infsof.2017.09.007} studied from library side,the impact of refactoring activities on evolving client-used APIs.
 Other works focused on the client side and how do client applications' developers react to the evolution of the libraries they depend on \cite{10.1145/2393596.2393662,7332471,7816485,7884616,10.1007/s11219-016-9344-4,10.1007/s10664-017-9521-5}. Jezek et al. \cite{10.1016/j.infsof.2015.02.014} treat both client and library perspectives. They studied the compatibility aspect of the APIs and the impacts of the library evolution on the programs using it. Further detail can be found in the PhD thesis of zaytsev Oleksandr \cite{zaytsev:tel-03998632}. Shaikh et al. \cite{10.1145/3092703.3092721} studied Behavioral Backward Incompatibilities. In their paper, they process a cross-version regression testing to understand the behavioral changes of APIs during evolution of software libraries.

 %ref :Automatically Generating Refactorings to Support API Evolution
% ref :Experience Paper: A Study on Behavioral Backward Incompatibilities of Java Software Libraries
 
% \input{RelatedWorkTable}
 
 %Our current work distinguishes from these code migration approaches~\cite{henkel2005catchup,nguyen2010graph,dagenais2011recommending,andersen2010generic,10.1145/3194793.3194798} by considering and reasoning on the changes at the metamodel level to match the different pattern usages of the generated code elements. 
 %and not at the code level. Thus, our approach treats way less changes to identify the impacted parts in the code than code migration approaches \cite{henkel2005catchup,nguyen2010graph,dagenais2011recommending,andersen2010generic}. 
% This is possible thanks to the abstraction offered by the metamodels. 
 %Whereas our work considers $one$ change of a given element, $n$ changes must be considered in order to fully migrate the code. 
 %
 % our approach VS api migration approaches
 % \cite{henkel2005catchup,andersen2010generic} 
% Moreover, there are similarities with migration approaches, %(example-based approaches and code transformation based approaches) in the aim, 
% which is evolving the dependent client code. But these approaches do not handle all the equivalents of the impacting metamodel changes we do (see Table~\ref{table:ResolutionsCatalog}), and that occurred in our case studies. They handle only a subset of changes~\cite{henkel2005catchup,andersen2010generic}. %The second main difference between our approach and the example-based approaches is that we don't use a pre-collected examples to learn how to evolve the additional code/\red{client}, we update the impacted parts of the additional code/\red{client} using only the set of detected metamodel changes \cite{6606596,9079197}. The main difference between our approach and code transformation based approaches is that they start by detecting the usages of the API, then they migrate the usages using a mapping between the old and the new version of the API. Our approach starts by detecting the changes of the metamodel then locating the impacted code before evolving it \cite{8443580}. The last main difference is that we validate our approach using test suites. Many other approaches don't treat validation step \cite{4814159}.
 %
 %Therefore, we did not consider them as a baseline because we know a priori that too many changes would not be treated, hence, the comparison would be unfair and biased. %Moreover, we used EMF for the implementation and the valuation, but our approach conceptually remains valid for other abstracted models that affect a Java code, such as in JHipster or OpenAPI.
 Other migration approaches~\cite{6606596,10.1145/3387905.3388608,9079197} rely on pre-collected examples to learn how to evolve the additional client code. Xu et al. \cite{8813263} instead of learning from code examples, it constructs a database of edits to use during clients' migration. %Our approach starts by detecting the changes of the metamodel and then locating the impacted code before co-evolving it without the need to learn from previous examples. 
 
 %Zhong et al. \cite{10.1145/3597503.3639084} propose "LibCatch", a compiler-directed tool for migrating API callsite of client code. LibCatch uses compiling error message to match it with an error type. Each error type has several corresponding migration actions to resolve the error. Then, it follows an optimization algorithm to find the right migration action to apply that minimizes the total number of compiling errors.
 Fazzini et al. \cite{10.1145/3387905.3388608} propose to check the code migration using differential testing but it still needs previous example-based learning to update the client code.
 Zhong et al. \cite{10.1145/3597503.3639084} proposes "LibCatch", a tool to co-evolve client code to APIs evolution by reducing the compilation errors. They do not consider the API changes to correctly propagate them to the code, which may lead to only eliminating the code errors while they could be incorrect resolutions. They further do not use any mechanism to check the behavioral correctness of the code co-evolution and with not comparison to a ground-truth.
 
Di Rocco et al.  \cite{DIROCCO2025107588} DeepMig: A transformer-based approach to support coupled library and code migrations : to add 
 
 %\blue{Here summarize quickly the table 9}
 %To summarize, our approach overcomes the following limitations of existing approaches:
 %\begin{itemize}
 %   \item No approach can automatically co-evolve the code without learning previously from exiting examples.
 %   \item Using change interface to detect the metamodel changes which allows handling any change type.
 %   \item Only Fazzini et al. \cite{10.1145/3387905.3388608} propose to check the code migration using differential testing but it still needs previous example-based learning to update the client code.
 %\end{itemize}
 
 
 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
 
 \subsection{Automatic Program Repair}
 \label{APR}
 
 
Xia et al. \cite{10.1109/ICSE48619.2023.00129} conducted a study on the application of Pretrained language models including both generative and infilling models on APR. This study investigated the ability of PLM in generating correct patches and its performance in ranking these patches, in addition to its performance in scaling.
Claire et al. \cite{goues2019automated} give a review article about Automatic Program Repair. Their paper present an overview of the APR techniques that has as input a buggy program and most of them use test suites for correctness checking.
 
Ruan et al. \cite{10638555} propose a co-evolutionary-based approach for APR. This means that they aim to evolves two populations simultaniously: a set of patches and a test suite. They implemented their workflow as a tool called EVOREPAIR as an extension of EVOSUITE.
 Xia et al \cite{10.1145/3650212.3680323} propose ChatRepair which is a fully automated conversation-driven tool. ChatRepair leverages ChatGPT to perform repair. This tool uses previously incorrect and plausible patches and test failure information as an immediate feedback to get better generated patches.

 In addition to migration approaches, extensive state of the art exists on program repair~\cite{goues2019automated,liu2020efficiency,monperrus2018automatic,gazzola2017automatic}. However, they do not repair code errors, but rather bugs that are found due to failing tests (e.g., Meng at al.~\cite{10.5555/2486788.2486855}). 
 They could be used as a next step after o co-evolution. 
 
Chen et al. \cite{9749899} propose LIANA wich is test-driven generate-and-validate program repair loop. It is based on repeatedly updating a statistical model by learning the features of the fix candidates. LIANA starts working using a given java program with a test suit that has at least one failing test. 
 

 %To refresh new references

 %Table~\ref{table:relatedWorkTable} 
 %summarizes closely related work from the metamodel and code co-evolution~\ref{metamodel_artifacts}, API-client code co-evolution~\ref{API_evolution}, and Automatic Program Repair~\ref{APR} categories. Moreover, it compares and highlights the advantages of our approach over those related work. In particular, we compare them with the following criteria: %selected the comparison features as follows : 
 
 %\begin{enumerate}
 	%\item Category: it represents the evolved artifact impacting the code.
 	%\item Approach: it gives the main idea of the approach.
 %	\item Automation: it indicates whether the approach is automatic, semi-automatic, or manual.
 %	\item "Requiring pre-learning": %many approaches need to analyse supplementary data to be capable of co-evolving the code. 
 %	this feature indicates if a given approach is standalone by immediately co-evolving the code or needs previous external code analysis to learn how to co-evolve client code by synthesising the co-evolution pattern.
 %	\item Changes types: it conveys the changes handled by each approach.
 %	\item Validation: to ensure that the co-evolution did not impact the behavior of the code, a post validation step can be added. This feature indicates if the approach uses any mean of checking behavioral correctness of the code after the co-evolution.
% \end{enumerate}
 
% From Table~\ref{table:relatedWorkTable}, we observe that only two existing approaches are fully automatic and all the rest are semi-automatic. Only three approaches are standalone without requiring a pre-learning phase before the co-evolution. Our approach is fully automatic and standalone. Moreover, several different set of changes are handled by each approach, varying from low AST changes to high level composed (refactoring likes) changes as in Table~\ref{table:ResolutionsCatalog} in our work. Finally, only Fazzini et al.~\cite{10.1145/3387905.3388608} proposed to validate the co-evolved Android Apps with a similar methodology as in our work based on tests' execution. 
 
 \subsection{Consistency checking }
 \label{Consistency_checking}
  Close to code co-evolution, Riedl et al.~\cite{riedl2014towards} proposed an approach to detect inconsistencies between UML models and code. Kanakis et al.~\cite{kanakis2019empirical} showed that inconsistency information of model change and code error can help to resolve them in the code, which is equivalent to our matched pattern usages. 
 Pham et al.~\cite{pham2017bidirectional} proposed an approach to synchronize architectural models and code with bidirectional mappings.
 %
 Jongeling et al.~\cite{jongeling2020towards} proposed an early approach for the consistency checking between system models and their implementations by focusing on recovering the traceability links between the models and the code. Jongeling et al.~\cite{jongeling2022Structural} later rely on the recovered traces to perform the consistency checking task.  %https://www.es.mdh.se/pdf_publications/5848.pdf
 %
 Zaheri et al.~\cite{zaheri2021towards} also proposed to support the checking of the consistency-breaking updates between models and generated artifacts, including the code. However,~\cite{pham2017bidirectional,jongeling2020towards,jongeling2022Structural,zaheri2021towards} do not focus on co-evolving the code to repair the inconsistencies with the models. 
 \subsection{Language evolution}
 
Language evolution is related to  various technological spaces ~\cite{ivanov2002technological}. Metamodels evolution ~\cite{favre2003meta} (Section \ref{coevolutionartifacts}), APIs evolution \cite{dig2006apis} (Section ~\ref{API_evolution}), grammars evolution in ~\cite{5279907}, schemas evolution~\cite{lammel2001format,meyer1996schema}, and ontologies evolution~\cite{flouris2008ontology}.
  
   There are two types of languages: General Purpose Languages (GPL) and Domain-Specific Languages(DSL). 
   
  
 % ref :Industrial experiences with the evolution of a DSL \cite{schuts2021industrial}
  DSL is strictly coupled to the domain and
  its requirements/capabilities at the time in which the DSL is written. If the domain requirements and/or capabilities change, then the DSL could become inadequate to deal with the changed domain. Schuts et al. \cite{schuts2021industrial} incrementally changed a five year old DSL called Azurion that supports multiple hardware preserving its behavior . initially these configurations were prefixed. After the evolution of the DSL, the configurations can be defined by the user. 
  %Domain experts no longer need DSL experts to define new configuration with new movements, states and zones.
 As DSLs evolve \cite{favre2005languages,herrmannsdorfer2013coupled}, the presence of inter-DSL dependencies in an MDSE ecosystem causes a ripple effect and increases costs of manual maintenance. Hence, an automatic approach is required to facilitate co-evolution of artifacts in MDSE ecosystems.
   Regarding Domain-Specific evolution, works treated this topic from many aspects, and from different ecosystems and case studies \cite{mengerink2016dsl}.
 In the one hand, there are opensource ecosystems case studies like The Graphical Modeling Framework (GMF)\footnote{https://eclipse.dev/modeling/gmp/?project=gmf-runtime} is a widely used open source framework for the model-driven development of diagram editors implemented on top of the Eclipse Modeling Framework (EMF).
%  Ref2 :DSL/Model Co-Evolution in Industrial EMF-Based MDSE Ecosystems \cite{mengerink2016dsl}
 
  
 % ref :Language Evolution in Practice: The History of GMF ,Herrmannsdoerfer, \cite{10.1007/978-3-642-12107-4_3}
Herrmannsdoerfer et al. present a method to investigate the evolution of modeling languages hint at the possible effects on the related language development artifacts  \cite{10.1007/978-3-642-12107-4_3}.
  
%  works treated the topic of dsl evolution from many aspects and from different ecosystems (case studies).
    
In the other hand, there are industrial  ecosystems case studies like CARM (Control Architecture Reference Model) is an industrial ecosystem for ASML \footnote{https://www.asml.com/en} is the world’s leading provider of complex lithography systems for the semiconductor industry  \cite{mengerink2016dsl}.

Regarding general purpose languages that are simply programming languages, their evolution consists mainly of improvements of syntax and semantics or feature additions that allows to some extent the stability of the code and do not break it.
 The evolution of the programming languages is due to two types of causes: 1) External, for example, for hardware changes, the control of business needs, or the progress of scientific research. 2) Internal for bug fixing, or improving the verbosity of the language \cite{urma2017programming}.
 %Particularly, the evolution of a programming language may be located in its API, f
 For example, the introduction of the generics since Java 5 \footnote{https://blogs.oracle.com/javamagazine/post/understanding-java-generics-part-1-principles-and-fundamentals} as new feature. Another example of an explicit semantic change in Python 2 an expression such as 1/2 returns 0. However, 1.0 / 2 returns 0.5. To contrast, in Python 3 the division operator has a float return type and the result is 0.5 whether the division operators are ints or of the them is a float.
 
 Every change to a programming language API has the potential to affect programs written in this language. 
 For example, Python 2 and 3 have major incompatibilities that leads to maintenance costs, particularly, due to Python’s dynamic typing, it is difficult to locate some errors that can  be found during program execution.
 It is worth noting that manually resolving the incompatibilities resulting from language evolution is a daunting task.
Dietrich et al. show that developers lack awareness of the 
 often present limitations and possible incompatibilities which make code maintenance a hard task \cite{dietrich2016java}.
 %https://dev.java/evolution/ 
Regarding programming languages evolution, many works were centered around change-impact analysis before proposing an adaptation approach \cite{arnold1996software,ren2004chianti,ryder2001change}

%subs-generated tests
 
 Urma et al.\cite{urma2017programming} propose PytypemonitorInfer, a dynamic light-weight type inference tool for Python to automatically provide insights useful for migration about a Python program. Few works were done for specific languages evolution, for example, Expansion and evolution of the R programming language regarding linguistic understanding of human language \cite{urma2017programming}.
 %these pharo api evolution zaytsev:tel-03998632
Another programming language, Pharo \cite{7332471} analyzed in their their empirical study the most important changes in Pharo API and their impact on different systems in Pharo ecosystem.
Ochoa et al. \cite{10.1145/3510455.3512783} propose Breakbot, a tool to analyze the impact of  the breaking changes of java libraries on their client code.

More insights about language evolution can be found the the dissertation of Raoul-Gabriel Urma \cite{urma2017programming}. 
	
 \section{Behavioral correctness of the co-evolution}
 \label{behavioralcorrectness}
 
% co-evolution is an evolution form
 
 
 %applicability of the other approches in co-evolutuion ? here or in the discussion
 
 
 %Code quality measurment : metrics, test suite ? fault localisation?, formal methods
 %Code evolution quality measurment 
% Code refactoring by definiton a set of operation that do not alter the behavior of the code 
 

%semantic errors only depend on the developer’s intentions 
%predetermined patches requires extensive understanding all possible situations in which an error may occur Zaheri thesis
 To ensure the behavioral correctness of a given version of the code, we can follow different methods. The first one is manual and exhaustive debugging to ensure that the code acts as expected. This method can be tedious and error prone for relatively complex code. Another method which is widely exploited is Testing. Testing in software engineering is a large research area with different approaches and tools. To check the behavioral correctness of a program, we can use Unit Testing through good quality unit tests that pass. In the case of more critical systems (Medical devices systems, autopilot systems, avionics engineering..etc), it is primordial to use formal methods like model checking or theorem proving \cite{ZHANG201312} (costly).
 
 In the context of code evolution, I need to verify that the code changes did not alter its behavior. 
 In more large perspective, I would like to check the impact of this evolution on the code, did it improve, kept, or alter the behavior of the code. From this point of view, I investigated the literature to explore the different approaches that are used for this purpose. In other words, I investigate the approaches  that check the impact of a code different type of evolution on the behavioral correctness of the code.
 
In automatic program repair, after fault localization, the goal is to remove bugs. The correctness of this bug removal is often checked using test suit that passes.
Ruan et al. \cite{10638555} propose an approach to check the correctness of the generated repair patches. Their approach is an extension of EVOSUITE, that has two outputs. First output is the repair patches of better quality and the second output is  the tests that proves the veracity of the patches.

In literature, different approaches exist for code translation from a programming language to another. Roziere et al. \cite{roziere2021leveraging} leverage generated unit tests to filter out invalid translations and reduce the noise in the generated translations to have better candidates.
%\cite{LIU2021110817}


Qi et al. \cite{8612557} also divide exsting approaches for APR assessment into two main approaches on assessing patched program correctness: formal specifications and APR assessment metrics with test suits.

Liu et al. \cite{LIU2021110817} states that in the literature, correctness is generally assessed manually by comparing the generated patches against the developer-provided patches. Moreover, the evaluation metrics of APR systems could be biased \cite{LIU2021110817}. In their paper, they exploit the number of bugs for which a correct patch is generated. Other metrics as the number of successfully fixed bugs with patches can pass all the given test cases. This metric can be biased when the generated patched pass all the tests but introduce other faults that are not covered by these tests \cite{LIU2021110817}.
 This paper proposes metrics that limit the biases when assessing APR tools. The list of the used metrics:\\
•  Upper bound Repair Performance metric aims to clearly provide an indication of the patch generation limitations when focusing on this part of the APR system (i.e., APR systems are given with the exact bug-fixing positions obtained from the ground of truth developers’ patches). 
\\
• Fault Localization Sensitiveness metric aims to assess the impact of the used fault localization on the repair performance of the APR system.\\
• Patch Generation Efficiency metrics aim to clarify the APR efficiency, the effort to yield a plausible/correct patch.\\
• Bug Diversity metrics aim at evaluating APR system performance from intrinsic attributes of bugs.\\
• Benchmark Overfitting metrics aim to clarify the difference of APR systems performance between in-the-lab and in-the-wild assessment settings.\\

In code refactoring, one of the followed approaches is to minimize the number of code smells in addition to a test suite that passes or both.
The term refactoring as introduced by Opdyke, means behavior-preserving program transformations for code quality improvement. 
Soares et al. \cite{soares2009generating} propose to check refactoring safety by checking errors due to non behavior-preserving transformations. Soares et al. \cite{soares2009generating} define this type of errors as semantic  errors. The current practice to avoid refactoring errors relies on compilation and tests to assure semantics preservation. Soares et al. \cite{soares2009generating}'s approach starts by identifying common methods between source and target source code (before and after refactoring). It then generates tests on the common methods, run them on source then the target if no test fail, developer will have more confidence the correctness of the refactorings.
Wahler et al. \cite{7816501} use static analysis and three software metrics: the number of duplicates and the number of duplicate lines using using PMD\footnote{https://pmd.github.io/} tool, and the number of warning using the tool Findbugs\footnote{https://plugins.jetbrains.com/plugin/4597-qaplug--findbugs}. These three metrics are used for objective evaluation. The usage of objective metrics is combined with Software Engineers judgment as subjective evaluation to validate refactorings and to improve the maintainability of their case study.

Da Silva et al. \cite{DASILVA2024112070} leverage generated unit tests to detect semantic conflicts in different merging scenarios, and differential generated unit tests generated and run on both commit the changed commit pairs. Their results show the efficiency of the generated unit tests and no conflict was wrongly detected.

Correa et al. \cite{correa2007refactoring} exploit regression testing to assess the correctness of OCL specifications' refactoring.
%In code co-evolution 
%Assumption: 
%Regression testing
%\textbf{Assumption}:
%Unit test can be used to check the behavioral correctness of the code at some state.
%If a transformation occurs in the code from a state to another, We can use unit tests (manually written or generated) to check if the code evolution has improved, kept, or altered the behavior of the code.
 
 %Talk about limitations?
  \section{LLMs for co-evolution }
  \label{llmsforcoevolution}
  Since their appearance in 2022 \footnote{texthttps://www.dataversity.net/a-brief-history-of-large-language-models/}, Large Language Models transformed the computer science industry and the industry of the world since computer science is concretely used everywhere. In this thesis, that started before this revolution, I found that it is important to investigate the path of LLMs and its intersection with the scope of our work. Thousands of scientific papers are produced in many domains to treat thousands of topics. In this section, I present the most related work to code co-evolution.
  
  Early studies on Copilot focus on the exploration of the security of the generated code~\cite{pearce2022asleep}, comparison of the performances of Copilot with mutation-based code generation techniques~\cite{sobania2022choose}, and  the impact on productivity and the usefulness of Copilot for developers~\cite{ziegler2022productivity,vaithilingam2022expectation}.
  Nguyen et al.~\cite{nguyen2022empirical} performed an early empirical study on the performance and understandability of Copilot generated code on~34 problems from Leetcode. 
  %
  Doderlein et al. \cite{doderlein2022piloting} extended the study of Nguyen et al. \cite{nguyen2022empirical} and run an empirical study on the effect of varying temperature and prompts on the generated code with Copilot and Codex. They used a total of 446 questions to solve from Leetcode and Human Eval data set.  
  Nathalia et al. \cite{nathalia2023artificial} evaluated the Performance and Efficiency of ChatGPT compared to beginners and experts software engineers. 
  %
  Yeticstiren et al. \cite{yeticstiren2023evaluating} compared the code quality generated from Copilot, CodeWhisperer, and ChatGPT, showing an advantage for ChatGPT in generating correct solutions. 
  %
  Guo et al. \cite{guo2023exploring} ran an empirical study on ChatGPT and its capabilities in refining code based on code reviews. 
  %
  Fu et al. \cite{fu2023chatgpt} also evaluated ChatGPT and its ability to detect, classify, and repair vulnerable code. 
  %
  Finally, Kabir et al. \cite{kabir2023empirical} evaluated ChatGPT ability to generate code and to maintain it by improving it based on a new feature description to add in the code. 
  %
 White et al. \cite{White2024} propose a set of prompt patterns for different tasks that can be used in different phases in the life cycle of a software development, for example: API generation prompt pattern, DSL creation prompt pattern, code quality, and refactoring prompt patterns.
  
Sridhara et al. \cite{sridhara2023chatgpt} explore how ChatGPT can be used in ambiguity resolution in Method Name Suggestion
   Log Summarization, Anaphora resolution, Python Type Inference,  Commit Message Generation, Code Review, Duplicate Bug Report Detection, Natural Language Code Search, Vulnerability Detection, Code Clone Detection, Test Oracle Generation, Code Generation from natural language, Merge Conflict Resolution, and Code Refactoring. Sridhara et al. \cite{sridhara2023chatgpt} found that Extract Method refactorings did not match with the developers' refactorings collected from Silva et al. \cite{10.1145/2950290.2950305}, however, when the authors checked the generated refactoring manually, they found that they are syntactically and semantically correct.

  Besides code generation and code documentation, the paper of Sadik et al. \cite{sadik2023analysis} investigates the potential application ChatGPT as an LLM for bug detection and refactoring particular code bad smell detection.
  Hemberg et al. \cite{hemberg2024evolving} explain their approach on how an algorithm, with the general algorithmic structure of an EA and evolutionary operators, can use an LLM to evolve code, how the operators are designed to formulate LLM prompts, task the LLM via the prompts, and process LLM responses, while code is represented as a sequence of text in code syntax. Its goal is to get the best solution code that fits the best the beforehand mentioned operators as hyper parameters of the genetic algorithm.
  
   Zhang et al.\cite{zhang2024copilot} aims to detect code smells in  copilot-generated python code and to evaluate copilot capacity in fixing these code smells. Results show that Copilot was able to detect 8 types of code smells out of 10 with 87.1\% as fixing rate showing the promising copilot in fixing python code smells.
  
 %%%%%%%%MDE 
 Moreover, other studies focused on evaluating LLMs in MDE activities. 
 \red{Chen et al. \cite{10344012} propose a comparative study between GPT-3.5 and GPT-4 in automatically generating domain models. This work shows that GPT-4 has better modeling results.}
 Chaaben et al. \cite{chaaben2023towards} showed how using few-shot learning with GTP3 model can be effective in model completion and in other modeling activities. 
 %
 Camara et al. \cite{camara2023assessment} further assessed how good ChatGPT is in generated UML models.
 %
 Finally, Abukhalaf \cite{AbukhalafHK23} run an empirical study on the quality of generated OCL constraints with Codex.
 
 However, these studies also focused on the ability of LLMs to generate MDE artifacts, such as models and constraints, but not on their co-evolution. 
 %In addition, most of these studies focus on generation part of LLMs. 
 Only Fu et al. \cite{fu2023chatgpt} looked at repairing vulnerable code with ChatGPT. 
 %
 Jiang et al. \cite{jiang2023selfevolve} proposed self-augmented code generation framework based on LLMs called SelfEvolve. SelfEvolve allows generating code and keep correcting it iteratively with the LLM. % to have better generated code. % but does not treat the metamodel and code coevolution problem.
 %
 Zhang et al. \cite{zhang2023multilingual} proposed Codeditor, an LLM based tool for code co-evolution between different programming languages. It learns code evolutions as edit sequences and then uses LLMs for multilingual translation.
  \section{Summary and Discussion}
  %Summary of the works cited above.
  After having reviewed the current landscape of metamodel and code co-evolution, this section synthesizes the key findings. This synthesis focuses on distilling insights from 1) the co-evolution of metamodels with models, constraints, and transformations, and code, 2) in addition to checking behavioral correctness of code evolution approaches, alongside 3) leveraging LLMs in code co-evolution. This synthesis also highlights the link to the challenges that I mentioned in the introduction.
  
  The factors of discussion when talking about the co-evolution of metamodels with models, constraints, and transformations, and code, are: 
  1- The degree of automation
  2- Impact analysis processing
  3- Assessing the behavioral correctness of the co-evolution
  
  Regarding metamodel and model co-evolution approaches, I remark that most automatic approaches are found under the category of predefined resolution strategies. The other ones are either transformation languages or learning approaches. Even most approaches use the metamodel changes in the process of adapting models, most of them do not explicitly study the impact of the metamodel evolution on the models except Hebig et al .\cite{hebig2016approaches}.
  
  Similarly, for metamodel and constraints approaches.
  Automatic approached use either predefined operations, pre-selected refactoring operations, or a machine learning approach.
  
 
  Most of the reviewed approaches of metamodel and transformations  do not explicitly study the impact of the metamodel evolution on the transformations. Except Kusel, et al.\cite{kusel2015consistent}.
  
  
  
  while evolving metamodels implies structural and possible semantic impact on different artifacts, the main focus is given to structural correctness. After browsing a large amount of papers ( the number of papers?), I find that only Kusel et al. \cite{kusel2015systematic} used Pamomo\cite{10.1007/s10515-012-0102-y} for semantic correctness verification when evolving OCL expressions.
  %Metamodel and model co-evolution :The point is that for metamodel and model co-evolution; predefined approaches exist, full automatic approaches exist
  
  Regarding the related work addressed in Section \ref{coevolutioncode} about code co-evolution, I selected the main related work and established a detailed comparison with it Table~\ref{table:relatedWorkTable}. My current work distinguishes from these approaches by considering and reasoning on the changes at the metamodel level to match the different pattern usages of the generated code elements (details in Section ??). This is possible thanks to the abstraction offered by the metamodels. 
  I compare them with the following criteria: %selected the comparison features as follows : 
  
  \begin{enumerate}
  	
  	\item Automation: it indicates whether the approach is automatic, semi-automatic, or manual.
  	\item "Requiring pre-learning": 
  	this feature indicates if a given approach is standalone by immediately co-evolving the code or needs previous external code analysis to learn how to co-evolve client code by synthesizing the co-evolution pattern.
  	\item Changes types: it conveys the changes handled by each approach.
  	\item Validation: to ensure that the co-evolution did not impact the behavior of the code, a post validation step can be added. This feature indicates if the approach uses any mean of checking behavioral correctness of the code after the co-evolution.  I observe that only two existing approaches are fully automatic and all the rest are semi-automatic. Only three approaches are standalone without requiring a pre-learning phase before the co-evolution. My approach is fully automatic and standalone. Moreover, several different set of changes are handled by each approach, varying from low AST changes to high level composed (refactoring likes) changes as in Table~\ref{table:ResolutionsCatalog} in my work. Finally, only Fazzini et al.~\cite{10.1145/3387905.3388608} proposed to validate the co-evolved Android Apps with a similar methodology as in our work based on tests' execution. 
  \end{enumerate}
  
  Regarding different approaches that I browse about behavioral correctness of co-evolution, I find that just few works dedicated a space to check behavioral correctness \cite{correa2007refactoring, kusel2015systematic}. Particularly, I noticed a considerable gap in assessing the behavioral correctness of metamodel and code co-evolution.
  %TODO reformulate 
  Finally, studies focused on either evaluating the ability of LLMs to generate qualitative code, refining it, repairing it if vulnerable, or augmenting it. However, none of them specifically explored the task of code co-evolution.
  %MDE
  studies also focused on the ability of LLMs to generate MDE artifacts, such as models and constraints, but not on their co-evolution. 
  
  no study investigated the ability of LLMs in the MDE problem of code co-evolution when metamodels evolve. I empirically evaluated how effective is Chagpt in solving this co-evolution problem.
  \input{./Chapitre1/RelatedWorkTable}
  
  TODO: Conclude the section to introduce next contributions
%  Regarding C1, code evolution 

 % Position of our contributions in the overview of SOTA. 
  
 % integrate the table of TSE 
  
 % Factors of comparing/discussing.
  
  %Talk about the case of coders who do not know MDE, do not have enough information about the metamodel.
  
 % Defined scope of the thesis.
  
 %TODO What has been done so far: 
%TODO Change detection
%TODO Metamodel-Transformation co-evolution
%TODO Metamodel-Constraint co-evolution
%TODO Metamodel-Model co-evolution
%TODO Metamodel-code co-evolution
%Discussion about automation degree of the approaches, best in cases and other cases not really

%TODO API-Client co-evolution

%TODO Language Evolution (e.g., Java V1 to V2)
%TODO Evolution in low-code platforms
%TODO Classification of related work 

%TODO Focus on limitations/research gap.

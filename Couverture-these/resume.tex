\markboth{}{}
% Plus petite marge du bas pour la quatrième de couverture
% Shorter bottom margin for the back cover
\newgeometry{inner=30mm,outer=20mm,top=40mm,bottom=20mm}

%insertion de l'image de fond du dos (resume)
%background image for resume (back)
\backcoverheader

% Switch font style to back cover style
\selectfontbackcover{ % Font style change is limited to this page using braces, just in case

\titleFR{Support de co-évolution du métamodèle et du code}

\keywordsFR{code, evolution, tests, les modèles de langage de grande taille}

\abstractFR{
	
	Les systèmes logiciels tendent à devenir de plus en plus complexes, ce qui engendre des coûts de maintenance élevés qui dépassent souvent les coûts de développement initiaux. L'ingénierie dirigée par les modèles (IDM) s'est imposée comme une approche incontournable pour simplifier le développement et accroître la productivité. Elle repose sur l'utilisation de métamodèles pour générer divers artefacts, y compris du code, que les développeurs améliorent ensuite avec du code additionnel pour développer les differents outils guistique nécessaire pour un langage logiciel, par exemple un éditeur, un vérificateur, un compilateur, des couches d'accès aux données, etc. Des infrastructures logicielles tels que Eclipse Modeling Framework (EMF) illustrent ce flux de travail, en générant des API Java qui sont ensuite enrichies à des fins de validation, de débogage et de simulation.
	
	L'un des principaux enjeux de l'EDM est l'évolution du métamodèle et son impact sur les artefacts connexes.
	Dans cette thèse, nous nous concentrons sur l'artefact du code et sa co-évolution avec le métamodèle en évolution. En outre, nous visons à vérifier l'exactitude comportementale de la co-évolution du métamodèle et du code. Enfin, avec l'émergence des LLM, nous explorons leur utilité pour le problème de co-évolution du métamodèle et du code.
	
	Cette thèse répond à ces problèmes en : 1) en proposant une nouvelle approche de co-évolution entièrement automatisée des métamodèles et du code. Cette approche associe les erreurs de compilation à des patrons d'utilisation des éléments du métamodèle afin de sélectionner des résolutions appropriées, puis 2) en proposant une approche automatique pour vérifier que la co-évolution du code entre différentes versions n'a pas impacté son comportement lorsque son métamodèle évolue.
	métamodèle évolue. Cette approche s'appuie sur l'isolations d'un sous ensembles des tests impactés avant et après la co-évolution.
	du code. 
	3) La dernière contribution concerne l'exploration de la capacité des LLM à proposer des co-évolutions correctes du code lorsque le métamodèle évolue. Cette approche est basée sur l'ingénierie des prompts, où nous concevons et générons des prompts en langage naturel pour faire co-évoluer au mieux le code impacté par l'évolution du métamodèle. 
	
	Les trois contributions ont été évaluées sur des projets EMF d'OCL, Modisco et Papyrus. L'évaluation montre que notre approche automatique de co-évolution du code résout~100\% des erreurs, avec~82\% de précision et~81\% de rappel, réduisant de manière significative l'effort manuel.
	De plus, notre deuxième contribution pour la vérification de la correction comportementale peut tracer et isoler avec succès les tests impactés par les changements de métamodèle représentant 5\% des tests. Ensuite, après l'exécution des tests tracés, la fluctuation du nombre de tests réussis, échoués ou erronés indique si la co-évolution du code est correcte ou non. L'utilisation de cette approche nous a permis de gagner 88\% sur le nombre de tests total et 84\% sur le temps d'exécution. Enfin, lors de l'évaluation de la capacité de Chatgpt dans la co-évolution de code, nous avons varié la valeur de la température, et la structure des prompts données. Nous avons constaté que des températures plus basses donnent de meilleurs résultats avec un taux de correction de 88,7\%. En ce qui concerne la structure de prompts, le fait d'inclure de l'information sur lien d'abstraction de l'erreur et la réclamer des réponses alternatives améliorent les co-évolutions proposées.
	
	
}



\titleEN{Supporting metamodel and code co-evolution}

\keywordsEN{code, evolution, tests, LLM}

\abstractEN{
%Context:
Software systems are becoming increasingly complex, leading to high maintenance costs that often exceed initial development expenses. Model-Driven Engineering (MDE) has emerged as a key approach to streamline development and improve productivity. It relies on the use of metamodels to generate various artifacts, including code, which developers later enhance with additional code to build the necessary language tooling, e.g.,editor, checker, compiler, data access layers, etc. Frameworks like Eclipse Modeling Framework (EMF) illustrate this workflow, generating Java APIs that are further extended for validation, debugging, and simulation.
%Problem:
One of the major challenges in MDE is the metamodel evolution and its impact on the related artifacts.
In this thesis, we focus on the code artifact and its co-evolution with evolving metamodel. Moreover, we aim to check the behavioral correctness of the metamodel and code co-evolution. Finally, with the emerbence of LLMs, we explore their usefulness for the metamodel and code co-evolution problem.
%Contributions
This thesis addresses these challenges by: 1) proposing a new fully automated co-evolution approach of metamodels and code. this approach is based on the pattern matching of compiling errors to select suitable resolutions, then 2) proposing an automatic approach to check the behavioral correctness of the code co-evolution between different releases of a language when its
metamodel evolves. This approach leverages the test suites of the original and evolved versions
of code. 3) the last contribution is about exploring LLMs' ability in proposing correct co-evolutions of the code when the metamodel evolves. This approach is based on prompt engineering, where we design and generate natural language prompts to best co-evolve the impacted code due to the metamodel evolution. 

The three contributions were evaluated on EMF projects from OCL, Modisco, and papyrus. The evaluation shows that our automatic code co-evolution approach resolves~100\% of errors, with~82\% precision and~81\% recall, significantly reducing manual effort.
Furthermore, our second contribution for behavioral correctness checking can successfully trace the impacted tests due to metamodel changes representing~5\% of the tests suit, thus isolating the relevant tests. Then, after the execution of the traced tests, the fluctuation in the number of passing, failing, or erroneous tests indicates whether the code co-evolution is correct or not.Using this approach allowed us to gain 88\% in the number of tests and 84\% in the execution time. Lastly, when evaluating the capacity of Chatgpt in code co-evolution, we variated the value of hyperparameter of temperature, and the structure of given prompts. We found that lower temperatures give better results with 88.7\% of correctness rate. Regarding the structure of the prompt, including the abstraction gap information of the error and asking for alternative answers improves the correctness of the proposed co-evolutions.

}

}

% Rétablit les marges d'origines
% Restore original margin settings
\restoregeometry

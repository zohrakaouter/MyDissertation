\chapter*{Résumé en Français}
\textbf{Contexte:} Les systèmes logiciels deviennent de plus en plus complexes, ce qui engendre une charge importante en matière de maintenance, souvent accompagnée de coûts élevés pouvant même dépasser ceux liés au développement initial \cite{https://doi.org/10.1049/sfw2.12075}.
 En 2001, le groupe Object Management Group (OMG) a introduit une approche l’Ingénierie Dirigée par les Modèles (IDM) \cite{brambilla2017model}. Depuis, cette méthode s’est largement répandue dans le développement et la maintenance des systèmes de grande envergure ainsi que des logiciels embarqués. Elle permet également d’optimiser la productivité des concepteurs.
 Son adoption permet également aux entreprises de réduire les délais (tant pour la conception que pour la mise sur le marché), de diminuer les dépenses (liées au développement, à l’intégration et à l’adaptation) et d’améliorer la durabilité ainsi que la compétitivité à l’échelle internationale.
l’Ingénierie Dirigée par les Modèles (IDM) utilise les modèles comme entité d'abstraction de haut niveau. Ces modèles sont utilisés comme une entrée pour la génération de plusieurs artéfacts : contraintes, transformations, instances de modèles, et le code. Dans le cadre de cette thèse, nous nous intéressons particulièrement au code. 
Le code généré à partir des modèles est ensuite enrichi pour ajouter d'autres fonctionnalités. Par exemple, le projet JHipster propose de générer, à partir de modèles d'entités, les différentes parties d'applications web modernes du côté client et serv eur. Un autre exemple populaire est celui d'OpenAPI, où de nombreux artefacts sont générés à partir d'une spécification d'API. Certaines plates-formes de développement low-code s'appuient sur certains des principes de l'IDM, avec des modèles de données et d'abstraction. Dans la plateforme d’Eclipse, le Framework de Modélisation Eclipse (EMF) est un autre exemple important. Sur la base d'un métamodèle, EMF génère des APIs de code Java, des adaptateurs et un éditeur. Ce code généré est ensuite enrichi par les développeurs pour offrir des fonctionnalités et des outils supplémentaires, tels que la validation, la simulation ou le débogage, etc. Par exemple, les implémentations Eclipse de UML\footnote{\url{https://www.eclipse.org/modeling/mdt/downloads/?project=uml2}} et BPMN\footnote{\url{https://www.eclipse.org/bpmn2-modeler/}} s’appuient sur les métamodèles UML et BPMN pour générer leur API de code correspondante. Par la suite, l’ensemble des outils et services complémentaires est développé à partir de cette API.

\textbf{Problématique:} 1) L’évolution des modèles impacte les artéfacts générés ce qui révèle un défi important sur leur co-évolution. Parmi ces artefacts, le code est particulièrement concerné. En effet, lorsqu’un métamodèle change et que l’API de code est régénérée, le code supplémentaire développé par les programmeurs peut être affecté. Il est alors essentiel d’assurer son adaptation pour maintenir la cohérence avec les nouvelles versions du métamodèle. Toutefois, si la co-évolution est réalisée manuellement, elle reste coûteuse en temps et en effort et est susceptible de provoquer des erreurs.
Afin de surmonter ces difficultés, les chercheurs ont exploré, depuis plusieurs décennies, différentes approches visant à automatiser ce processus. Ces travaux ne se sont pas limités au code, mais ont concerné l’ensemble des artefacts de l’écosystème MDE, en mettant l'accent sur l’automatisation. D’autres aspects, comme l’optimisation et la résilience à l'évolution du métamodèle, ont également été étudiés. 
De nombreuses recherches ont abordé la question de la co-évolution en MDE. Certains travaux~\cite{riedl2014towards,kanakis2019empirical,pham2017bidirectional,jongeling2020towards,jongeling2022Structural,zaheri2021towards} se sont concentrés sur la vérification de la cohérence entre les modèles et le code, sans pour autant traiter leur co-évolution. D’autres études~\cite{yu2012maintaining,Khelladi2020} ont proposé des solutions permettant d’adapter le code aux évolutions du métamodèle, mais avec certaines limites. Certaines approches se focalisent uniquement sur l’API de code générée, sans prendre en compte le code additionnel, et se contentent de maintenir une traçabilité bidirectionnelle entre le modèle et l’API. D’autres offrent une co-évolution semi-automatique nécessitant l’intervention des développeurs, mais sans mécanisme de validation après la co-évolution, ni de comparaison avec une référence~\cite{9079197,10.5555/2486788.2486855,6062100,dagenais2011recommending,5070565,henkel2005catchup,10.1145/1932682.1869486,10.1145/3194793.3194798,Khelladi2020}.

Dans cette thèse, nous proposons une approche automatisée pour gérer l’impact de l’évolution des métamodèles sur le code, accompagnée d’un processus de validation permettant de valider la co-évolution.

2) Dans tout système reposant sur l’Ingénierie Dirigée par les Modèles, les éléments du métamodèle sont utilisés dans le code API et puis dans le code additionnel. L’évolution du métamodèle sera propagée dans le code co-évolué et son comportement peut être altéré. D’où l’importance de vérifier la l'exactitude de la co-évolution. 

Dans une perspective plus large, peu de travaux ont été consacrés à la vérification de la correction de l’évolution du code en général.
Ge et al. \cite{10.1145/2568225.2568280} proposent une méthode pour vérifier l'xexactitude des refactorisations. Hors du cadre de l’évolution du code, on trouve des approches de sélection de tests incrémentiels telles que Infinitest\footnote{\url{https://infinitest.github.io/doc/eclipse}}, EKSTAZI~\cite{7203050} et Moose~\cite{ducasse2000moose}. Ces outils, Infinitest, EKSTAZI et Moose, ont pour objectif d'analyser les modifications du code de manière incrémentale afin de sélectionner uniquement les tests impactés dans la version évoluée du code.

3) Dans l’écosystème de l’Ingénierie Dirigée par les Modèles (IDM), la co-évolution des métamodèles et du code peut être considérée comme l’une des nombreuses tâches existantes, aux côtés de la génération de modèles et de la génération de code. Depuis leur apparition, les modèles de langage de grande taille ( abrégé LLM de l'anglais large language model) ont été appliqués à divers domaines de la recherche scientifique, notamment en ingénierie logicielle et en IDM. Cependant, à notre connaissance, l’exploration des LLMs pour la co-évolution des métamodèles et du code n’a pas encore été abordée.

Dans le domaine de l’Ingénierie Logicielle, Fu et al. \cite{fu2023chatgpt} ont évalué la capacité de ChatGPT à détecter, classer et corriger du code vulnérable. Kabir et al. \cite{kabir2023empirical} ont étudié son aptitude à générer du code et à le maintenir en l’améliorant sur la base de nouvelles spécifications fonctionnelles. Zhang et al. \cite{zhang2023multilingual} ont proposé CodEditor, un outil basé sur les LLMs pour la co-évolution du code entre différents langages de programmation. Cet outil apprend les évolutions sous forme de séquences d’édition et utilise des LLMs pour assurer une traduction multilingue du code.

Par ailleurs, d’autres travaux ont évalué l’usage des LLMs dans les activités de IDM. Chen et al. \cite{10344012} et Camara et al. \cite{camara2023assessment} ont exploré l’utilisation de ChatGPT pour la génération de modèles. Chaaben et al. \cite{chaaben2023towards} ont démontré que l’apprentissage par quelques exemples (few-shot learning) avec le modèle GPT-3 pouvait être efficace pour la complétion de modèles et d’autres activités de modélisation.

\textbf{Contributions:} Pour répondre à ces problème, je propose les contributions suivantes:
1) Tout d’abord, je propose une approche entièrement automatisée de co-évolution du code en réponse à l’évolution des métamodèles. Cette approche est guidée par le compilateur. Elle est basée sur la correction des erreurs de compilation causées par l'évolution du métamodèle. Les erreurs sont analysées afin de les associer à des patrons d'utilisation des éléments du métamodèle qui ont évolué. Suite à cela, on arrive à sélectionner une ou plusieurs résolutions à appliquer pour chaque erreur ( dépendamment du nombre du changements du métamodèle impactants), et donc co-évoluer les erreurs du code automatiquement. 

L'évaluation de cette approche a été réalisée sur neuf projets Eclipse issus d'OCL, Modisco et Papyrus, selon quatre axes :~1) Évaluation de la correction de la co-évolution à l’aide de tests unitaires générés automatiquement.~2) Vérification de la correction comportementale en exécutant des tests unitaires avant et après la co-évolution automatique du code.~3) Comparaison avec l’approche de co-évolution semi-automatique de référence~\cite{Khelladi2020}.~4) Comparaison avec l’outil populaire de corrections rapides (Quick Fixes).
Un prototype sous forme de plugin Eclipse a été mis en ligne (lien). Les résultats obtenus montrent que notre approche atteint une précision moyenne de 82\% et un rappel moyen de 81\%, avec des variations allant de 48\% à 100\% pour la précision et le rappel.
%TODO CHeck results for all the 4 axes
2) Ma seconde contribution est une approche visant à aider les développeurs à vérifier l'exactitude de la co-evolution, autrement dit, que la co-évolution n'a pas altéré le comportement du code. Mon approche exploite les tests unitaires avant et après la co-évolution et génère un rapport visuel indiquant les tests réussis, échoués et erronés avant et après l’évolution du code. Ce rapport permet d’obtenir une meilleure compréhension de la co-évolution et de son impact sur le code.
Avant de procéder à une évaluation quantitative, une étude utilisateur a été menée afin d’évaluer la difficulté de tracer manuellement des tests impactés après l’évolution du métamodèle et la co-évolution du code, de plus la difficulté d'investiguer l'éxactitude de la co-évolution.
J'ai évalué notre approche sur 18 projets Eclipse issus d’OCL, Modisco, Papyrus et EMF, en utilisant à la fois des tests unitaires générés automatiquement et des tests écrits manuellement pour deux projets OCL. L’analyse quantitative de son utilité a révélé une réduction de 88\% du nombre de tests exécutés et une diminution de 84\% du temps d’exécution. Un prototype sous forme de plugin Eclipse est disponible en ligne (lien).



3) Dans ma dernière contribtion, j'explore la capacité des modèles de langage de grande taille (LLMs) à proposer des co-évolutions correctes dans le cadre de l’évolution conjointe des métamodèles et du code. Un prototype sous forme de plugin Eclipse est disponible en ligne (lien).

Notre approche a été évaluée à l’aide de ChatGPT version 3.5 sur sept projets Eclipse issus des métamodèles évolués d’OCL et Modisco. L’évaluation a pris en compte plusieurs paramètres : la variation de la température, la structure des invites (prompts) et une comparaison avec les corrections rapides (Quick Fixes) des IDE, utilisées comme référence.

Les résultats montrent que ChatGPT parvient à co-évoluer correctement 88,7\% des erreurs, avec un taux de correction variant entre 75\% et 100\%. En modifiant les invites, nous avons observé une amélioration de la correction dans deux variantes et une diminution dans une autre. De plus, la variation du paramètre de température a révélé de meilleurs résultats avec des valeurs plus faibles. Enfin, nous avons constaté que les co-évolutions générées par ChatGPT surpassent largement les corrections rapides des IDE.


 %De plus, une étape de vérification de la pertinence et l’exactitude de la co-évolution est nécessaire pour s’assurer que cette dernière n’altère pas le comportement du code. Les travaux menés dans cette thèse jusqu’à maintenant avaient pour but de répondre aux deux objectifs suivants : 1) la co-évolution automatique du code suite à l’évolution des modèles et 2) la validation de l’exactitude de cette co-évolution.
%Dans un premier temps, nous nous sommes focalisés sur le premier objectif, à savoir la co-évolution automatique du code. Nous avons proposé une approche pour co-évoluer automatiquement le code supplémentaire en fonction des changements du modèle. Cette approche est basée sur la correction des erreurs de compilation causées par l'évolution du modèle. Les erreurs sont analysées afin de les associer à des patrons d'utilisation des éléments des modèles qui ont évolué. 
%Dans un deuxième temps, nous nous sommes intéressés au deuxième objectif, notamment la validation de la co-évolution. Nous avons proposé une approche pour vérifier le comportement du code avant et après sa co-évolution suite à l'évolution d'un modèle. Cette approche se base sur les suites de tests unitaires. L'idée principale c'est de tracer les changements du modèle à travers le code généré puis à travers le code supplémentaire, jusqu'à atteindre les tests unitaires pour isoler les tests impactés par l'évolution du modèle. Cet isolement des tests unitaires est fait avant et après l'évolution du modèle sur la première version du code et leurs tests ainsi que leur version co-évoluée. L'étape suivante est de comparer les tests impactés avant et après pour avoir un aperçu sur l'exactitude de la co-évolution du code, c.à.d., si la co-évolution est correcte ou pas. Après avoir isolé les tests impactés avant et après la co-évolution, nous comparons ces tests en établissant une correspondance entre eux et en les exécutant. Ensuite, nous fournissons un rapport visuel pour faciliter au développeur leur analyse et ainsi prendre une décision concernant la co-évolution effectuée. 
